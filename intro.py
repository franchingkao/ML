# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mHZx8tdMamd0MFR4BKAYyach-F8Sl0ok
"""

pip install torch==1.6.0 torchvision

from torch.utils.data import Dataset, DataLoader

"""Step1: define the function"""

# 定義Dataset
class MyDataset(Dataset):
  # 讀取資料
  def __init__(self, file):
    self.file = ...
  # 回傳資料
  def __getitem__(self, index):
    return self.data[index]
  # 計算batch
  def __len__(self):
    return len(self.data)

dataset = MyDataset(file)
dataloader = DataLoader(dataset, batch_size=5, shuffle=True) #shuffle通常traning=1 testing=0

# 確認資料維度方法: .shape()
# 維度互換: .transpose(0,1)
# 移除維度: .squeeze(0) *適用第一個維度
# 增加維度: .unsqueeze(1) *適用第一個維度
# 合併維度: .Cat([x,y,z], dim=1) *沿著第一個維度合併xyz

# 在CPU運作: .to('cpu')
# 在GPU運作: .to('cuda')
# 確認電腦是否有GPU: torch.cuda.is_available()

# 計算梯度
# x = torch.tensor([[1., 0.],[-1., 1.]], requires_grad=True)
# z = x.pow(2).sum()
# z.backward()
# x.grad

# 非線性函數
# Sigmoid Activation
# nn.Sigmoid()

# ReLU Activation
# nn.ReLU()

import torch.nn as nn

class MyModel(nn.Module):
  # 定義模型
  def __init__(self):
    super(MyModel, self).__init__()
    self.net = nn.Sequential()(
        nn.Linear(10,32),
        nn.Sigmoid(),
        nn.Linear(32,1)
    )
  # 計算運算輸出
  def forward(self, x):
    return self.net(x)

# 此寫法與上列同

import torch.nn as nn

class MyModel(nn.Module):
  # 定義模型
  def __init__(self):
    super(MyModel, self).__init__()
    nn.Linear(10,32)
    nn.Sigmoid()
    nn.Linear(32,1)
  
  # 計算運算輸出
  def forward(self, x):
    out = self.layer1(x)
    out = self.layer2(out)
    out = self.layer3(out)
    return out

"""Step 2: loss function"""

# mean squared Error *for regression tasks
# cross entropy *for claasification

"""Step 3: optimization"""

# w*, b* = arg min L
# 1.歸零
# 2.回推計算梯度
# 3.根據梯度調整參數

# W對L的微分和B對L的微分(負斜率>增加W; 正斜率>減少W; 斜率大就多一點)
# 停止尋找W時機: 1.太多沒耐心了 2.微分為0

# 包起來 定義模型 移至cpu/gpu 定義loss 定義alg 
dataset = MyDataset(file) 
tr_set = DataLoader(dataset, 16, shuffle=True)
model = MyModel().to(device)
criterion = nn.MSELoss()
optimizer = torch.option.SGD(model.parameters(), 0.1)

# training
for epoch in range(n_epochs): #定義訓練次數
  model.train()
  for x, y in tr_set:
    eptimizer.zeo_grad() #歸零
    x, y = x.to(device), y.to(device) #移至cup/gpu
    pred = model(z)
    loss = criterion(pred, y)
    loss.backward()
    optimizer.step()

# validation loop
model.eval()
total_loss = 0
for x, y in dv_set:
  x, y = x.to(device), y.to(device) #移至cup/gpu
  with torch.no_grad():
    pred = model(z)
    loss = criterion(pred, y)
  total_loss += loss.cpu.item() * len(x)
  avg+loss = total_loss / len(dev_set.dataset)

# testing
model.eval()
preds = []
for x in tt_set:
  x = x.to(device)
  with torch.no_grad():
    pred = model(x)
    preds.append(pred.cpu)
# 關掉梯度?
# 測試時不需要調整參數, 避免拿測試資料訓練模型[連結文字](https://)

"""存取與讀取訓練好的模型"""

#save
torch.save(model.state_dict(), path)
#load
ckpt = torch.load(path)
model.load_state_dict(ckpt)

# audio/text/computer vision
